{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\morga\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "import spacy\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from src import nlp_utils\n",
    "from src.process_text_variables import contracted_words_dict, stop_words_dict, punc, stop_words_incl_in_sentiment_dict \n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\morga\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Import and Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\morga\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'stop_words_incl_in_sentiment_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-397c37bbc8bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mwsm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/wallstreet_master.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mstop_words_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstop_words_dict\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstop_words_incl_in_sentiment_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mwsm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tokens'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwsm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'contentWithHTMLTag'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnlp_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontracted_words_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop_words_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_len\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stop_words_incl_in_sentiment_dict' is not defined"
     ]
    }
   ],
   "source": [
    "wsm = pd.read_csv('data/wallstreet_master.csv')\n",
    "stop_words_dict = stop_words_dict + stop_words_incl_in_sentiment_dict\n",
    "wsm['tokens'] = wsm['contentWithHTMLTag'].apply(lambda x: nlp_utils.process_text(x, contracted_words_dict, punc, stop_words_dict, min_len=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\morga\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "all_docs_tokenized = wsm['tokens'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_docs_tokenized[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Create Bigrams/Trigrams and Remove Neglible Words Based on Parts of Sentence (PoS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\morga\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "# English multi-task CNN trained on OntoNotes. Assigns context-specific token vectors, POS tags, dependency parse and named entities.\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADJ', 'PROPN']):\n",
    "    texts_revised =[]\n",
    "    for post in texts:\n",
    "        doc = nlp(' '.join(post))\n",
    "        texts_revised.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_revised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function Used to Calculate Score that Corresponds to \"threshold\" hyperparameter**\n",
    "\n",
    "```\n",
    "def original_scorer(worda_count, wordb_count, bigram_count, len_vocab, min_count, corpus_word_count):\n",
    "   #...\n",
    "   \"\"\"\n",
    "    worda_count : int\n",
    "        Number of occurrences for first word.\n",
    "    wordb_count : int\n",
    "        Number of occurrences for second word.\n",
    "    bigram_count : int\n",
    "        Number of co-occurrences for phrase \"worda_wordb\".\n",
    "    len_vocab : int\n",
    "        Size of vocabulary.\n",
    "    min_count: int\n",
    "        Minimum collocation count threshold.\n",
    "    corpus_word_count : int\n",
    "        Not used in this particular scoring technique.\n",
    "    \"\"\"\n",
    "    #...\n",
    "\n",
    "    return (bigram_count - min_count) / worda_count / wordb_count * len_vocab\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\morga\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "min_count = 10\n",
    "# greater the threshold, the lower the number of words.\n",
    "threshold = 50\n",
    "\n",
    "\n",
    "bigram = gensim.models.Phrases(all_docs_tokenized, min_count=min_count, threshold=threshold)\n",
    "trigram = gensim.models.Phrases(bigram[all_docs_tokenized], threshold=threshold)\n",
    "\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\morga\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "docs_incl_bigrams = make_bigrams(all_docs_tokenized)\n",
    "\n",
    "docs_lemmatized = lemmatization(docs_incl_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADJ', 'PROPN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\morga\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['understand',\n",
       " 'right',\n",
       " 'want',\n",
       " 'move',\n",
       " 'russia',\n",
       " 'find',\n",
       " 'teach',\n",
       " 'hacker',\n",
       " 'ask',\n",
       " 'kinda',\n",
       " 'joke',\n",
       " 'day_change',\n",
       " 'everythingcc_bank',\n",
       " 'log',\n",
       " 'room']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_lemmatized[22222]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Create Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\morga\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go\n"
     ]
    }
   ],
   "source": [
    "# Bag of Words corpus\n",
    "id2word = corpora.Dictionary(docs_lemmatized)\n",
    "\n",
    "# Create unique ID for each word in corpus.\n",
    "bow_corpus = [id2word.doc2bow(post) for post in  docs_lemmatized]\n",
    "\n",
    "# Use the unique id as the index in id2word to see the corresponding token.\n",
    "print(id2word[3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\morga\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# Tfidf corpus\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "tfidf_corpus = tfidf[bow_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4) Develop LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\morga\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# BoW \n",
    "lda_bow = gensim.models.ldamodel.LdaModel(corpus=bow_corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=20, \n",
    "                                           random_state=3,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\morga\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# Tf-Idf\n",
    "lda_tfidf = gensim.models.ldamodel.LdaModel(corpus=tfidf_corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=20, \n",
    "                                           random_state=3,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW TOPICS:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\morga\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'lda_bow' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-3a3998564c03>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'BoW TOPICS:'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlda_bow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_topics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lda_bow' is not defined"
     ]
    }
   ],
   "source": [
    "print('BoW TOPICS:')\n",
    "for t in lda_bow.print_topics(): \n",
    "    print(t)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tf-Idf TOPICS:\n",
      "(0, '0.043*\"escrow\" + 0.031*\"sign\" + 0.022*\"access\" + 0.019*\"release\" + 0.018*\"lol\" + 0.016*\"encrypt\" + 0.015*\"pas\" + 0.012*\"multiple\" + 0.011*\"admin\" + 0.008*\"document\"')\n",
      "\n",
      "\n",
      "(1, '0.103*\"bank\" + 0.094*\"guide\" + 0.032*\"fullz\" + 0.028*\"interested\" + 0.025*\"usa\" + 0.025*\"cc\" + 0.023*\"paypal\" + 0.022*\"high_quality\" + 0.021*\"note\" + 0.021*\"login\"')\n",
      "\n",
      "\n",
      "(2, '0.034*\"fresh\" + 0.020*\"bin\" + 0.000*\"bump\" + 0.000*\"_\" + 0.000*\"record_cashout\" + 0.000*\"phished_rule\" + 0.000*\"room\" + 0.000*\"everythingcc_bank\" + 0.000*\"day_change\" + 0.000*\"picsou\"')\n",
      "\n",
      "\n",
      "(3, '0.026*\"verify\" + 0.019*\"worth\" + 0.019*\"save\" + 0.018*\"dream\" + 0.016*\"picture\" + 0.014*\"interesting\" + 0.014*\"advertise\" + 0.012*\"original\" + 0.010*\"choose\" + 0.008*\"photo\"')\n",
      "\n",
      "\n",
      "(4, '0.081*\"drop\" + 0.040*\"way\" + 0.034*\"come\" + 0.032*\"cash\" + 0.030*\"friend\" + 0.022*\"score\" + 0.018*\"cheap\" + 0.017*\"good_luck\" + 0.016*\"call\" + 0.015*\"private\"')\n",
      "\n",
      "\n",
      "(5, '0.018*\"mate\" + 0.011*\"cancel\" + 0.003*\"match\" + 0.000*\"bump\" + 0.000*\"_\" + 0.000*\"record_cashout\" + 0.000*\"phished_rule\" + 0.000*\"room\" + 0.000*\"everythingcc_bank\" + 0.000*\"picsou\"')\n",
      "\n",
      "\n",
      "(6, '0.061*\"weed\" + 0.053*\"wait\" + 0.007*\"url\" + 0.000*\"bump\" + 0.000*\"_\" + 0.000*\"record_cashout\" + 0.000*\"phished_rule\" + 0.000*\"room\" + 0.000*\"everythingcc_bank\" + 0.000*\"picsou\"')\n",
      "\n",
      "\n",
      "(7, '0.029*\"easy\" + 0.024*\"idea\" + 0.021*\"hear\" + 0.019*\"clear\" + 0.017*\"item\" + 0.015*\"depend\" + 0.014*\"trouble\" + 0.011*\"worry\" + 0.011*\"decrypt\" + 0.010*\"box\"')\n",
      "\n",
      "\n",
      "(8, '0.109*\"pm\" + 0.062*\"hash\" + 0.058*\"guy\" + 0.031*\"tell\" + 0.029*\"stuff\" + 0.024*\"able\" + 0.020*\"eu\" + 0.018*\"setup\" + 0.017*\"thing\" + 0.017*\"lab\"')\n",
      "\n",
      "\n",
      "(9, '0.083*\"profile\" + 0.046*\"message\" + 0.039*\"wsm\" + 0.039*\"money\" + 0.037*\"want\" + 0.027*\"see\" + 0.023*\"customer\" + 0.022*\"ship\" + 0.022*\"feedback\" + 0.019*\"regard\"')\n",
      "\n",
      "\n",
      "(10, '0.058*\"name\" + 0.055*\"uk\" + 0.044*\"lot\" + 0.036*\"put\" + 0.034*\"number\" + 0.030*\"tx\" + 0.015*\"hi\" + 0.014*\"amazing\" + 0.009*\"error\" + 0.005*\"dead\"')\n",
      "\n",
      "\n",
      "(11, '0.046*\"hope\" + 0.037*\"problem\" + 0.032*\"sample\" + 0.032*\"may\" + 0.018*\"tip\" + 0.012*\"tutorial\" + 0.009*\"secure\" + 0.009*\"tab\" + 0.008*\"ca\" + 0.007*\"double\"')\n",
      "\n",
      "\n",
      "(12, '0.048*\"move\" + 0.014*\"app\" + 0.012*\"advice\" + 0.010*\"enter\" + 0.007*\"mobile\" + 0.004*\"white\" + 0.004*\"image\" + 0.000*\"bump\" + 0.000*\"_\" + 0.000*\"phished_rule\"')\n",
      "\n",
      "\n",
      "(13, '0.066*\"answer\" + 0.031*\"batch\" + 0.016*\"e\" + 0.016*\"member\" + 0.015*\"copy\" + 0.010*\"view\" + 0.009*\"format\" + 0.008*\"book\" + 0.006*\"matter\" + 0.006*\"actual\"')\n",
      "\n",
      "\n",
      "(14, '0.026*\"track\" + 0.017*\"datum\" + 0.005*\"selling\" + 0.000*\"bump\" + 0.000*\"_\" + 0.000*\"record_cashout\" + 0.000*\"phished_rule\" + 0.000*\"room\" + 0.000*\"everythingcc_bank\" + 0.000*\"picsou\"')\n",
      "\n",
      "\n",
      "(15, '0.033*\"market\" + 0.026*\"store\" + 0.021*\"order\" + 0.018*\"offer\" + 0.017*\"write\" + 0.016*\"good\" + 0.016*\"card\" + 0.016*\"help\" + 0.015*\"account\" + 0.015*\"new\"')\n",
      "\n",
      "\n",
      "(16, '0.043*\"nice\" + 0.031*\"mean\" + 0.016*\"stay\" + 0.008*\"meet\" + 0.000*\"bump\" + 0.000*\"_\" + 0.000*\"record_cashout\" + 0.000*\"phished_rule\" + 0.000*\"room\" + 0.000*\"everythingcc_bank\"')\n",
      "\n",
      "\n",
      "(17, '0.009*\"icq\" + 0.000*\"eggcarriage\" + 0.000*\"uin\" + 0.000*\"bro\" + 0.000*\"planning\" + 0.000*\"handle\" + 0.000*\"room\" + 0.000*\"tomorrow\" + 0.000*\"quietbillz\" + 0.000*\"tox\"')\n",
      "\n",
      "\n",
      "(18, '0.000*\"socksnow\" + 0.000*\"readout\" + 0.000*\"technitium.com/tmac/-ccleanerjust\" + 0.000*\"switcherthis\" + 0.000*\"string.fullz\" + 0.000*\"stickwe\" + 0.000*\"torrent\" + 0.000*\"servers.now\" + 0.000*\"password.at\" + 0.000*\"proxifierwhat\"')\n",
      "\n",
      "\n",
      "(19, '0.031*\"join\" + 0.017*\"lead\" + 0.013*\"date\" + 0.012*\"several\" + 0.009*\"build\" + 0.008*\"verification\" + 0.003*\"submit\" + 0.000*\"bump\" + 0.000*\"_\" + 0.000*\"record_cashout\"')\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\morga\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "print('Tf-Idf TOPICS:')\n",
    "for t in lda_tfidf.print_topics(): \n",
    "    print(t)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Model Performance Evaluation\n",
    "\n",
    "### Bag-of-Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\morga\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity:  -17.050147888887906\n",
      "Coherence Score:  0.37779212769099185\n"
     ]
    }
   ],
   "source": [
    "# The lower, the better.\n",
    "print('Perplexity: ', lda_model.log_perplexity(bow_corpus))\n",
    "\n",
    "coherence_model_bow = CoherenceModel(model=lda_model, texts=docs_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_bow = coherence_model_bow.get_coherence()\n",
    "print('Coherence Score: ', coherence_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf-Idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\morga\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity:  -20.00055618928151\n",
      "Coherence Score:  0.3155524293093971\n"
     ]
    }
   ],
   "source": [
    "print('Perplexity: ', lda_tfidf.log_perplexity(tfidf_corpus))\n",
    "\n",
    "coherence_model_tfidf = CoherenceModel(model=lda_tfidf, texts=docs_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_tfidf = coherence_model_tfidf.get_coherence()\n",
    "print('Coherence Score: ', coherence_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
