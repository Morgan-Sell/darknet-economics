{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\morga\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (web_app_utils.py, line 6)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m\"C:\\Users\\morga\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\"\u001b[0m, line \u001b[0;32m3417\u001b[0m, in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-9cf40dabd974>\"\u001b[1;36m, line \u001b[1;32m17\u001b[1;36m, in \u001b[1;35m<module>\u001b[1;36m\u001b[0m\n\u001b[1;33m    from src import utils, nlp_topic_utils, web_app_utils\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\morga\\OneDrive\\Documents\\22_Udacity_ML_Nanodegree\\darknet-economics\\src\\web_app_utils.py\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    %matplotlib inline\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "from src import utils, nlp_topic_utils, web_app_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualizations for Website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wallstreet = pd.read_csv('data/wallstreet_master.csv', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wallstreet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily Forum Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_daily_post_freq(series):\n",
    "    '''\n",
    "    Interactive line plot showing the number of plots per day.\n",
    "    '''\n",
    "    daily_post_freq = pd.DataFrame(series.value_counts()).reset_index()\n",
    "    daily_post_freq.columns = ['date', 'count']\n",
    "    daily_post_freq.sort_values(['date'], axis=0, inplace=True)\n",
    "    fig = px.line(data_frame=daily_post_freq, x='date', y='count', labels= {'date': 'Date', 'count': '# of Posts'})\n",
    "    fig.update_layout(width=1500, height=600)\n",
    "    fig.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = wallstreet['post_date_only']\n",
    "\n",
    "web_app_utils.plot_daily_post_freq(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_wordcloud(pd_series, max_words):\n",
    "    '''\n",
    "    Generates wordcloud.\n",
    "    '''\n",
    "\n",
    "    series_as_str = pd_series.astype('str')\n",
    "    joined_wordcloud_text = ' '.join(str_series)\n",
    "\n",
    "    wordcloud = WordCloud(background_color='white', max_words=max_words, contour_color='steelblue')\n",
    "    wordcloud.generate(joined_wordcloud_text)\n",
    "\n",
    "    plt.figure(figsize=(20,7))\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_wordcloud(wallstreet['wordcloud_text'], 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Time-Series Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "si_analyzer = SentimentIntensityAnalyzer()\n",
    "wallstreet['compound_sentiment'] = wallstreet['wordcloud_text'].apply(lambda x: si_analyzer.polarity_scores(x)['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1 = wallstreet['sentiment_all']\n",
    "\n",
    "# utils.stats_summary(arr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_sentiment_time_series(sentiment_arr)\n",
    "\n",
    "groupby1 = wallstreet.groupby('post_date_only')['compound_sentiment'].mean()\n",
    "daily_sentiment = pd.DataFrame(groupby1).reset_index()\n",
    "daily_sentiment.columns=['date', 'sentiment']\n",
    "fig = px.line(data_frame=daily_sentiment, x='date', y='sentiment')#, labels= {'date': 'Date', 'count': '# of Posts'})\n",
    "fig.show();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wallstreet_for_sentiment = wallstreet[wallstreet['post_date_only'] > '2017-10-14'].copy()\n",
    "\n",
    "arr2 = wallstreet_for_sentiment['sentiment_all']\n",
    "sentiment_lt_avg = wallstreet_for_sentiment['sentiment_all'].mean()\n",
    "\n",
    "utils.stats_summary(arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_sentiment = wallstreet_for_sentiment.groupby('post_date_only')['compound_sentiment'].aggregate(['min', 'max', 'mean', 'median', 'std', 'count']).reset_index()\n",
    "daily_sentiment.columns = ['date', 'min', 'max', 'mean', 'median', 'std_dev', 'count']\n",
    "\n",
    "daily_sentiment['less_1_std_dev'] = daily_sentiment['mean'] - daily_sentiment['std_dev']\n",
    "daily_sentiment['plus_1_std_dev'] = daily_sentiment['mean'] + daily_sentiment['std_dev']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_rng = daily_sentiment['date'].values\n",
    "date_rng_rev = date_rng[::-1]\n",
    "\n",
    "lifetime_avg_arr = np.full(len(date_rng), sentiment_lt_avg)\n",
    "mean_arr = daily_sentiment['mean'].values\n",
    "median_arr = daily_sentiment['median'].values\n",
    "\n",
    "upper_lim_arr = daily_sentiment['plus_1_std_dev'].values\n",
    "lower_lim_arr = daily_sentiment['less_1_std_dev'].values\n",
    "lower_lim_arr = lower_lim_arr[::-1]\n",
    "\n",
    "max_arr = daily_sentiment['max'].values\n",
    "min_arr = daily_sentiment['min'].values\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.update_layout(width=1800, height=700,yaxis=dict(range=[-1.1,1.1]))\n",
    "\n",
    "#fig.add_trace(go.Scatter(x=date_rng, y=median_arr, name='Lifetime Avg.', line=dict(color='#FFA15A', width=2)))\n",
    "#fig.add_trace(go.Scatter(x=date_rng, y=median_arr, name='Daily Median', line=dict(color='#B6E880', width=2)))\n",
    "#fig.add_trace(go.Scatter(x=date_rng, y=mean_arr, name='Daily Avg.', line=dict(color='royalblue', width=2)))\n",
    "\n",
    "\n",
    "fig.add_trace(go.Scatter(x=date_rng, y=upper_lim_arr+lower_lim_arr, fill='toself', fillcolor='rgba(231,107,243,0.2)',\n",
    "                         line_color='rgba(255,255,255,0)', name='One Std. Dev. Range'))\n",
    "\n",
    "# fig.add_trace(go.Scatter(x=date_rng, y=lower_lim_arr, name='Lower Lim', stackgroup='one', line=dict(color='firebrick', width=0.5)))\n",
    "# fig.add_trace(go.Scatter(x=date_rng, y=upper_lim_arr, name='Upper Lim', stackgroup='one', line=dict(color='firebrick', width=0.5)))\n",
    "\n",
    "\n",
    "fig.add_trace(go.Scatter(x=date_rng, y=min_arr, name='Min', line=dict(color='green', width=2, dash='dot')))\n",
    "fig.add_trace(go.Scatter(x=date_rng, y=max_arr, name='Max', line=dict(color='green', width=2, dash='dot')))\n",
    "fig.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(figure(20,8))\n",
    "# Plot record 2005 to 2014 daily temperature range.\n",
    "ax.plot(date_rng, tmp_max, linestyle = '-', color = 'green', linewidth = 1)\n",
    "plt.plot(days, tmp_min, linestyle = '-', color = 'yellow', linewidth = 1)\n",
    "plt.fill_between(days, tmp_max, tmp_min, color='grey', alpha=0.2)\n",
    "# Plot the 2015 temperatures that were greater than 2005 to 2014 maximum temperature.\n",
    "plt.plot(days, tmax_15_grtr, 'ro')\n",
    "# Plot the 2015 temperatures that were less than 2005 to 2014 minimum temperature.\n",
    "plt.plot(days, tmin_15_less, 'bo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_sentiment_v2['std_dev'].hist(bins=40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
